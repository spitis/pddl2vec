{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyperplan import _parse, _ground\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from abc import ABC, abstractmethod\n",
    "from embedding import NaiveEmb, IntegerEmb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gym Env Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, gym.spaces as spaces\n",
    "from gym.utils import seeding\n",
    "from pyperplan import _parse, _ground\n",
    "from embedding import NaiveEmb, IntegerEmb\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pddl2env import PddlBasicEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = PddlBasicEnv('pddl_files/logistics/domain.pddl',\n",
    "                 'pddl_files/logistics/problogistics-50-0.pddl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutexes = defaultdict(set)\n",
    "for f in env.task.facts:\n",
    "  a = f.replace('(','').replace(')','')\n",
    "  key_val = a.split(' ')\n",
    "  mutexes[' '.join(key_val[:2])].add(key_val[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.get_actions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  13,   34,   49,   79,  108,  199,  201,  252,  335,  354,  365,\n",
       "         411,  420,  495,  499,  599,  609,  646,  666,  689,  719,  833,\n",
       "         896,  898,  950,  992, 1057, 1151, 1213, 1382, 1418, 1431, 1473,\n",
       "        1491, 1509, 1642, 1654, 1665, 1727, 1870, 1877, 1948, 1966, 1982,\n",
       "        2048, 2103, 2128, 2173, 2255, 2436, 2467, 2520, 2526, 2530, 2580,\n",
       "        2654, 2709, 2773, 2780, 2799, 2812, 2815, 2818, 2893, 2934, 2997,\n",
       "        3055, 3119, 3214, 3337, 3434, 3577, 3597]), -1, 0, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(env.E.state_to_emb(env._actions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PddlSimpleMultiGoalEnv(gym.GoalEnv):\n",
    "  def __init__(self, domain, instance, embedding_fn=IntegerEmb):\n",
    "    self.problem = _parse(domain_file=domain, problem_file=instance)\n",
    "    self.task = _ground(self.problem)\n",
    "    self.E = embedding_fn(self.task)\n",
    "    \n",
    "    mutexes = defaultdict(set)\n",
    "    for f in self.task.facts:\n",
    "      a = f.replace('(','').replace(')','')\n",
    "      key_val = a.split(' ')\n",
    "      mutexes[' '.join(key_val[:2])].add(key_val[2])\n",
    "\n",
    "      \n",
    "    special_obj = ''.join([i for i in list(self.task.goals)[0].split(' ')[1] if not i.isdigit()])\n",
    "    \n",
    "    self.mutexes = {k:v for k, v in mutexes.items() if special_obj in k}\n",
    "    self._goal_set = [f for f in self.task.facts if special_obj in f]\n",
    "    assert(len(self._goal_set) == sum([len(v) for v in self.mutexes.values()]))\n",
    "    \n",
    "    self.goal_len = sum([len(v) for v in self.mutexes.values()])\n",
    "    \n",
    "    self.basic_init = frozenset([f for f in env.task.initial_state if not special_obj in f])\n",
    "    \n",
    "    self.action_space = spaces.Discrete(1000)\n",
    "    self.observation_space = spaces.Dict(dict(\n",
    "            desired_goal=spaces.MultiBinary(self.goal_len),\n",
    "            achieved_goal=spaces.MultiBinary(self.goal_len),\n",
    "            observation=spaces.MultiBinary(len(self.task.facts)),\n",
    "        ))\n",
    "    \n",
    "    self.reward_range = (-1., 0.)\n",
    "\n",
    "    self.seed()\n",
    "    self._state = None\n",
    "    self._goal = None\n",
    "    self._actions = None\n",
    "    self.reset()\n",
    "\n",
    "  def seed(self, seed=None):\n",
    "    self.np_random, seed = seeding.np_random(seed)\n",
    "    return [seed]\n",
    "  \n",
    "  def get_actions(self):\n",
    "    return [self.E.state_to_emb(a) for a in self._actions]\n",
    "\n",
    "  def get_actions_for_emb(self, state_emb):\n",
    "    actions = [\n",
    "      next_state for _, next_state in self.task.get_successor_states(\n",
    "        self.E.emb_to_state(state_emb)\n",
    "      )\n",
    "    ]\n",
    "    return [self.E.state_to_emb(a) for a in actions]\n",
    "  \n",
    "  def _sample_goal(self):\n",
    "    return frozenset(['({} {})'.format(k, np.random.choice(list(v))) for k, v in self.mutexes.items()])\n",
    "  \n",
    "  def reset(self):\n",
    "    self._state = self.basic_init.union(self._sample_goal())\n",
    "    self._goal = self._sample_goal()\n",
    "    self._goal_emb = self.E.state_to_emb(self._goal)\n",
    "    self._actions = [\n",
    "        next_state\n",
    "        for op, next_state in self.task.get_successor_states(self._state)\n",
    "    ]\n",
    "    return self._get_obs()\n",
    "  \n",
    "  def _get_obs(self):\n",
    "    return {\n",
    "      'observation': self.E.state_to_emb(self._state),\n",
    "      'achieved_goal': self.E.state_to_emb(self._state.intersection(self._goal_set)),\n",
    "      'desired_goal': self._goal_emb\n",
    "    }\n",
    "\n",
    "  def render(self, mode=None):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def close(self):\n",
    "    pass\n",
    "\n",
    "  def step(self, action):\n",
    "    next_state = self.E.emb_to_state(action)\n",
    "    if next_state not in self._actions:\n",
    "      raise ValueError('bad action!')\n",
    "    self._state = next_state\n",
    "    self._actions = [\n",
    "        next_state\n",
    "        for op, next_state in self.task.get_successor_states(self._state)\n",
    "    ]\n",
    "\n",
    "    reward = -1\n",
    "    if len(self._goal.intersection(self._state)) == len(self._goal):\n",
    "      reward = 0\n",
    "\n",
    "    return self._get_obs(), reward, reward + 1, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = PddlSimpleMultiGoalEnv('pddl_files/logistics/domain.pddl',\n",
    "                 'pddl_files/logistics/problogistics-50-0.pddl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05030386, -0.01080087, -0.01502595,  0.04162736,  0.07952476,\n",
       "         0.0474224 , -0.0305328 ,  0.04548838,  0.06364573,  0.0182024 ,\n",
       "        -0.04808633,  0.00967416, -0.05022812, -0.01181706,  0.07991284,\n",
       "         0.03560514]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now get an N-dimensional continuous embedding using a trainable embedding matrix\n",
    "# This is equivalent to having an N-dimensional embedding for each \"fact/fluent\", and then adding them together.\n",
    "N = 16\n",
    "W_emb = np.random.normal(0., 1e-2, (len(task.facts), N))\n",
    "\n",
    "# So now the initial embedding of the initial state is:\n",
    "np.expand_dims(naive_emb(task.initial_state), 0).dot(W_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter embedding\n",
    "\n",
    "- this is non-trivial... we should discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
